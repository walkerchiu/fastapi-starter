services:
  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - '5672:5672'
      - '15672:15672'
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ['CMD', 'rabbitmq-diagnostics', '-q', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  backend:
    build:
      context: ./apps/backend
      dockerfile: Dockerfile
    ports:
      - '8000:8000'
    environment:
      - APP_NAME=FastAPI Backend (Dev)
      - DEBUG=true
      - CORS_ORIGINS=["http://localhost:3000"]
      - S3_ENDPOINT_URL=http://seaweedfs:8333
      - S3_ACCESS_KEY_ID=admin
      - S3_SECRET_ACCESS_KEY=admin
      - S3_BUCKET_NAME=uploads
      - S3_REGION=us-east-1
      - RABBITMQ_ENABLED=true
      - RABBITMQ_HOST=rabbitmq
    volumes:
      - ./apps/backend/src:/app/src:ro
    depends_on:
      seaweedfs:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test:
        [
          'CMD',
          'python',
          '-c',
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

  seaweedfs:
    image: chrislusf/seaweedfs:latest
    ports:
      - '9333:9333'
      - '8080:8080'
      - '8333:8333'
      - '18080:18080'
    command: 'server -s3 -dir=/data -master.dir=/data/master -volume.dir.idx=/data/volume -filer.dir.idx=/data/filer'
    environment:
      - S3_ACCESS_KEY=admin
      - S3_SECRET_KEY=admin
    volumes:
      - seaweedfs-data:/data
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--spider',
          '-q',
          'http://localhost:9333/cluster/status',
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

volumes:
  rabbitmq-data:
  seaweedfs-data:
